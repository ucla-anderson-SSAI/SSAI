{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 1: imports + load\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "URL = \"https://raw.githubusercontent.com/ucla-anderson-SSAI/SSAI/main/HandMSales_fullspan.csv\"\n",
        "df = pd.read_csv(URL)\n",
        "df[\"month_ts\"] = pd.to_datetime(df[\"month_ts\"], format=\"%m/%d/%y\", errors=\"coerce\")\n",
        "df = df.sort_values([\"article_id\", \"month_ts\"]).reset_index(drop=True)\n",
        "print(\"[INFO] raw df:\", df.shape)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 2: shared feature engineering\n",
        "# lags\n",
        "df[\"lag_m1\"] = df.groupby(\"article_id\")[\"demand\"].shift(1)\n",
        "df[\"lag_m2\"] = df.groupby(\"article_id\")[\"demand\"].shift(2)\n",
        "df[\"lag_m3\"] = df.groupby(\"article_id\")[\"demand\"].shift(3)\n",
        "\n",
        "# 3-month moving average of past demand\n",
        "df[\"ma_3\"] = (\n",
        "    df.groupby(\"article_id\")[\"demand\"]\n",
        "      .shift(1)\n",
        "      .rolling(3, min_periods=1)\n",
        "      .mean()\n",
        "      .reset_index(level=0, drop=True)\n",
        ")\n",
        "\n",
        "# long-run avg demand up to last month\n",
        "g = df.groupby(\"article_id\")[\"demand\"]\n",
        "df[\"cum_sum\"] = g.cumsum().shift(1)\n",
        "df[\"cum_cnt\"] = g.cumcount()\n",
        "df[\"mean_prev\"] = df[\"cum_sum\"] / df[\"cum_cnt\"].replace(0, np.nan)\n",
        "\n",
        "# fill early rows\n",
        "df[[\"lag_m1\",\"lag_m2\",\"lag_m3\",\"ma_3\",\"mean_prev\"]] = (\n",
        "    df[[\"lag_m1\",\"lag_m2\",\"lag_m3\",\"ma_3\",\"mean_prev\"]].fillna(0)\n",
        ")\n",
        "\n",
        "# drop helpers\n",
        "df = df.drop(columns=[\"cum_sum\",\"cum_cnt\"])\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 3: cold-start split (first row per article is test)\n",
        "df[\"is_first_for_article\"] = (\n",
        "    df.groupby(\"article_id\")[\"month_ts\"].rank(method=\"first\").eq(1)\n",
        ")\n",
        "\n",
        "test = df[df[\"is_first_for_article\"]].copy()\n",
        "train = df[~df[\"is_first_for_article\"]].copy()\n",
        "\n",
        "print(\"[INFO] cold-start split\")\n",
        "print(f\"train rows: {len(train)} | test rows: {len(test)}\")\n",
        "print(f\"train articles: {train['article_id'].nunique()} | test articles: {test['article_id'].nunique()}\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 4: base feature lists + scaling\n",
        "base_numeric = [\n",
        "    \"mean_price\",\n",
        "    \"price_change\",\n",
        "    \"lag_m1\",\n",
        "    \"lag_m2\",\n",
        "    \"lag_m3\",\n",
        "    \"ma_3\",\n",
        "    \"mean_prev\",\n",
        "]\n",
        "\n",
        "dummy_cols = [\n",
        "    c for c in df.columns\n",
        "    if (c.startswith(\"month_\") and c != \"month_ts\") or c.startswith(\"channel_\")\n",
        "]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_s = train.copy()\n",
        "test_s  = test.copy()\n",
        "train_s[base_numeric] = scaler.fit_transform(train[base_numeric])\n",
        "test_s[base_numeric]  = scaler.transform(test[base_numeric])\n",
        "\n",
        "X_tr_base = train_s[base_numeric + dummy_cols].to_numpy()\n",
        "X_te_base = test_s[base_numeric + dummy_cols].to_numpy()\n",
        "y_tr = train[\"demand\"].to_numpy()\n",
        "y_te = test[\"demand\"].to_numpy()\n",
        "\n",
        "print(\"[INFO] base shapes:\", X_tr_base.shape, X_te_base.shape)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 5: build embeddings from ALL text fields\n",
        "target_dim = 128\n",
        "text_cols = [\n",
        "    \"detail_desc\",\n",
        "    \"product_type_name\",\n",
        "    \"graphical_appearance_name\",\n",
        "    \"colour_group_name\",\n",
        "    \"index_group_name\",\n",
        "    \"garment_group_name\",\n",
        "]\n",
        "\n",
        "embed_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "uniq = df[[\"article_id\"] + text_cols].drop_duplicates(\"article_id\").fillna(\"\")\n",
        "uniq[\"combined_text\"] = uniq[text_cols].agg(\" \".join, axis=1)\n",
        "\n",
        "emb = embed_model.encode(uniq[\"combined_text\"].tolist(), show_progress_bar=False)[:, :target_dim]\n",
        "\n",
        "emb_cols = [f\"emb_{i}\" for i in range(target_dim)]\n",
        "emb_df = pd.DataFrame(emb, columns=emb_cols)\n",
        "emb_df.insert(0, \"article_id\", uniq[\"article_id\"].values)\n",
        "\n",
        "trainE = train_s.merge(emb_df, on=\"article_id\", how=\"left\")\n",
        "testE  = test_s.merge(emb_df, on=\"article_id\", how=\"left\")\n",
        "\n",
        "X_tr_emb = trainE[emb_cols].to_numpy()\n",
        "X_te_emb = testE[emb_cols].to_numpy()\n",
        "print(\"[INFO] embeddings shapes:\", X_tr_emb.shape, X_te_emb.shape)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 6: Model 1 \u2014 numeric only\n",
        "model1 = LassoCV(cv=3, max_iter=5000, random_state=0, n_jobs=-1)\n",
        "model1.fit(X_tr_base, y_tr)\n",
        "pred1 = model1.predict(X_te_base)\n",
        "\n",
        "r2_1 = r2_score(y_te, pred1)\n",
        "rmse_1 = np.sqrt(mean_squared_error(y_te, pred1))\n",
        "mae_1 = mean_absolute_error(y_te, pred1)\n",
        "print(f\"Model 1 (numeric) -> R2={r2_1:.3f} RMSE={rmse_1:.2f} MAE={mae_1:.2f}\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 7: Model 2 \u2014 numeric + interactions\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
        "poly_tr = poly.fit_transform(train_s[base_numeric])\n",
        "poly_te = poly.transform(test_s[base_numeric])\n",
        "\n",
        "X_tr_2 = np.hstack([train_s[dummy_cols].to_numpy(), poly_tr])\n",
        "X_te_2 = np.hstack([test_s[dummy_cols].to_numpy(),  poly_te])\n",
        "\n",
        "model2 = LassoCV(cv=3, max_iter=5000, random_state=0, n_jobs=-1)\n",
        "model2.fit(X_tr_2, y_tr)\n",
        "pred2 = model2.predict(X_te_2)\n",
        "\n",
        "r2_2 = r2_score(y_te, pred2)\n",
        "rmse_2 = np.sqrt(mean_squared_error(y_te, pred2))\n",
        "mae_2 = mean_absolute_error(y_te, pred2)\n",
        "print(f\"Model 2 (numeric + interactions) -> R2={r2_2:.3f} RMSE={rmse_2:.2f} MAE={mae_2:.2f}\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 8: Model 3 \u2014 embeddings only\n",
        "model3 = LassoCV(cv=3, max_iter=5000, random_state=0, n_jobs=-1)\n",
        "model3.fit(X_tr_emb, y_tr)\n",
        "pred3 = model3.predict(X_te_emb)\n",
        "\n",
        "r2_3 = r2_score(y_te, pred3)\n",
        "rmse_3 = np.sqrt(mean_squared_error(y_te, pred3))\n",
        "mae_3 = mean_absolute_error(y_te, pred3)\n",
        "print(f\"Model 3 (embeddings only) -> R2={r2_3:.3f} RMSE={rmse_3:.2f} MAE={mae_3:.2f}\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 9: Model 4 \u2014 numeric + embeddings\n",
        "X_tr_4 = np.hstack([X_tr_base, X_tr_emb])\n",
        "X_te_4 = np.hstack([X_te_base, X_te_emb])\n",
        "\n",
        "model4 = LassoCV(cv=3, max_iter=5000, random_state=0, n_jobs=-1)\n",
        "model4.fit(X_tr_4, y_tr)\n",
        "pred4 = model4.predict(X_te_4)\n",
        "\n",
        "r2_4 = r2_score(y_te, pred4)\n",
        "rmse_4 = np.sqrt(mean_squared_error(y_te, pred4))\n",
        "mae_4 = mean_absolute_error(y_te, pred4)\n",
        "print(f\"Model 4 (numeric + embeddings) -> R2={r2_4:.3f} RMSE={rmse_4:.2f} MAE={mae_4:.2f}\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 10: Model 5 \u2014 numeric + interactions + embeddings\n",
        "X_tr_5 = np.hstack([X_tr_2, X_tr_emb])\n",
        "X_te_5 = np.hstack([X_te_2, X_te_emb])\n",
        "\n",
        "model5 = LassoCV(cv=3, max_iter=5000, random_state=0, n_jobs=-1)\n",
        "model5.fit(X_tr_5, y_tr)\n",
        "pred5 = model5.predict(X_te_5)\n",
        "\n",
        "r2_5 = r2_score(y_te, pred5)\n",
        "rmse_5 = np.sqrt(mean_squared_error(y_te, pred5))\n",
        "mae_5 = mean_absolute_error(y_te, pred5)\n",
        "print(f\"Model 5 (numeric + interactions + embeddings) -> R2={r2_5:.3f} RMSE={rmse_5:.2f} MAE={mae_5:.2f}\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 11: summary\n",
        "summary = pd.DataFrame({\n",
        "    \"model\": [\n",
        "        \"Model 1: numeric\",\n",
        "        \"Model 2: numeric+interactions\",\n",
        "        \"Model 3: embeddings only\",\n",
        "        \"Model 4: numeric+embeddings\",\n",
        "        \"Model 5: numeric+interactions+embeddings\",\n",
        "    ],\n",
        "    \"R2\":   [r2_1, r2_2, r2_3, r2_4, r2_5],\n",
        "    \"RMSE\": [rmse_1, rmse_2, rmse_3, rmse_4, rmse_5],\n",
        "    \"MAE\":  [mae_1, mae_2, mae_3, mae_4, mae_5],\n",
        "})\n",
        "print(summary)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}