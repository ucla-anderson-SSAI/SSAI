{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MGMT298D: Science and Strategy of AI\n",
        "**Instructor:** Professor Siddiq  \n",
        "**Student:** _Your Name Here_\n",
        "\n",
        "This notebook walks through a small demand-modeling exercise using H&M-style SKU data.\n",
        "You will:\n",
        "1. Load and clean the data.\n",
        "2. Focus on a single product type.\n",
        "3. Split SKUs into train/test so we test on **new products**.\n",
        "4. Fit a baseline LASSO.\n",
        "5. (Optionally) add a feature-engineered version.\n",
        "6. Reflect on the modeling choices.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---------------------------------------------------------\n",
        "# 1. Imports and basic setup\n",
        "# ---------------------------------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "MONTHS = [\n",
        "    \"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\n",
        "    \"July\",\"August\",\"September\",\"October\",\"November\",\"December\"\n",
        "]\n",
        "\n",
        "def report_metrics(y_true, y_pred, label=\"\"):\n",
        "    \"\"\"Print R\u00b2, RMSE, and MAE for easy comparison.\"\"\"\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    rmse = mean_squared_error(y_true, y_pred) ** 0.5\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    print(f\"{label}R\u00b2={r2:.3f}, RMSE={rmse:.2f}, MAE={mae:.2f}\")\n",
        "\n",
        "def show_top_coeffs(model, feature_names, k=12):\n",
        "    \"\"\"Show the k largest coefficients in absolute value.\"\"\"\n",
        "    coefs = pd.Series(model.coef_, index=feature_names)\n",
        "    top = coefs.abs().sort_values(ascending=False).head(k)\n",
        "    print(\"\\n[Top features by |coefficient|]\")\n",
        "    print(top)\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---------------------------------------------------------\n",
        "# Helper: visualize LASSO cross-validation path and sparsity\n",
        "# ---------------------------------------------------------\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_lasso_cv(model, model_name=\"LASSO\"):\n",
        "    \"\"\"Plot CV error vs alpha and print sparsity info.\"\"\"\n",
        "    if not hasattr(model, \"alphas_\") or not hasattr(model, \"mse_path_\"):\n",
        "        print(f\"[WARN] {model_name}: no CV path available.\")\n",
        "        return\n",
        "\n",
        "    mean_mse = np.mean(model.mse_path_, axis=1)\n",
        "    std_mse = np.std(model.mse_path_, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.semilogx(model.alphas_, mean_mse)\n",
        "    plt.fill_between(model.alphas_, mean_mse - std_mse, mean_mse + std_mse, alpha=0.2)\n",
        "    plt.axvline(model.alpha_, linestyle=\"--\")\n",
        "    plt.xlabel(\"Alpha (penalty)\")\n",
        "    plt.ylabel(\"Cross-validated MSE\")\n",
        "    plt.title(f\"{model_name}: CV Error vs Alpha\")\n",
        "    plt.show()\n",
        "\n",
        "    n_nonzero = np.sum(model.coef_ != 0)\n",
        "    print(f\"[INFO] {model_name} selected alpha = {model.alpha_:.4g}\")\n",
        "    print(f\"[INFO] Nonzero coefficients: {n_nonzero} / {len(model.coef_)}\")\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and lightly clean the dataset\n",
        "\n",
        "- CSV you shared has columns like `id, demand, price, name, ... April, August, ...`.\n",
        "- We will rename the odd `Transparent.1` column if it exists.\n",
        "- Then we will filter to **one** product name that actually exists (default: `Vest top`).\n",
        "- Change `CSV_PATH` or `PRODUCT_NAME` as needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2A. Product Types Available",
        "",
        "Below is the full list of product types found in the dataset.",
        "Please **choose one** and assign it to `PRODUCT_NAME` in the code cell below (e.g., `\"Hoodie\"` or `\"Bra\"`).",
        "",
        "```",
        "Alice band",
        "Baby Bib",
        "Backpack",
        "Bag",
        "Ballerinas",
        "Beanie",
        "Belt",
        "Bikini top",
        "Blanket",
        "Blazer",
        "Blouse",
        "Bodysuit",
        "Bootie",
        "Boots",
        "Bra",
        "Bra extender",
        "Bracelet",
        "Braces",
        "Bucket hat",
        "Cap",
        "Cap/peaked",
        "Cardigan",
        "Chem. cosmetics",
        "Coat",
        "Costumes",
        "Cushion",
        "Dog Wear",
        "Dress",
        "Dungarees",
        "Earring",
        "Earrings",
        "Felt hat",
        "Fine cosmetics",
        "Flat shoe",
        "Flat shoes",
        "Flip flop",
        "Garment Set",
        "Giftbox",
        "Gloves",
        "Hair clip",
        "Hair string",
        "Hair/alice band",
        "Hairband",
        "Hat/beanie",
        "Hat/brim",
        "Heeled sandals",
        "Heels",
        "Hoodie",
        "Jacket",
        "Jumpsuit/Playsuit",
        "Keychain",
        "Kids Underwear top",
        "Leg warmers",
        "Leggings/Tights",
        "Long John",
        "Necklace",
        "Night gown",
        "Nipple covers",
        "Other accessories",
        "Other shoe",
        "Outdoor overall",
        "Outdoor trousers",
        "Outdoor Waistcoat",
        "Polo shirt",
        "Pumps",
        "Pyjama bottom",
        "Pyjama jumpsuit/playsuit",
        "Pyjama set",
        "Ring",
        "Robe",
        "Sandals",
        "Sarong",
        "Scarf",
        "Sewing kit",
        "Shirt",
        "Shorts",
        "Shoulder bag",
        "Side table",
        "Skirt",
        "Sleep Bag",
        "Sleeping sack",
        "Slippers",
        "Sneakers",
        "Socks",
        "Soft Toys",
        "Straw hat",
        "Sunglasses",
        "Sweater",
        "Swimsuit",
        "Swimwear bottom",
        "Swimwear set",
        "Swimwear top",
        "T-shirt",
        "Tailored Waistcoat",
        "Tie",
        "Top",
        "Tote bag",
        "Trousers",
        "Umbrella",
        "Underdress",
        "Underwear body",
        "Underwear bottom",
        "Underwear corset",
        "Underwear set",
        "Underwear Tights",
        "Unknown",
        "Vest top",
        "Wallet",
        "Watch",
        "Waterbottle",
        "Wedge",
        "Weekend/Gym bag",
        "Wood balls",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---------------------------------------------------------\n",
        "# 2. Load and basic cleaning\n",
        "# ---------------------------------------------------------\n",
        "CSV_PATH = \"HMData.csv\"  # change to your actual path if needed\n",
        "\n",
        "print(\"[INFO] Loading data\u2026\")\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(\"[INFO] Raw shape:\", df.shape)\n",
        "\n",
        "# Fix awkward column name\n",
        "if \"Transparent.1\" in df.columns:\n",
        "    df = df.rename(columns={\"Transparent.1\": \"Transparent_color\"})\n",
        "\n",
        "# Choose a product that exists in this CSV\n",
        "PRODUCT_NAME = \"Vest top\"  # e.g., \"Bra\", \"Underwear Tights\"\n",
        "df = df[df[\"name\"] == PRODUCT_NAME].copy()\n",
        "if df.empty:\n",
        "    raise ValueError(f\"No rows found for name == {PRODUCT_NAME!r}\")\n",
        "\n",
        "print(f\"[INFO] After filtering to product '{PRODUCT_NAME}':\", df.shape)\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train/test split by SKU and keep Q4 in test\n",
        "\n",
        "We want to test on **new products**:\n",
        "1. Split unique `id` into train/test.\n",
        "2. Train = all rows for train SKUs.\n",
        "3. Test = Q4 rows (Oct/Nov/Dec) for test SKUs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---------------------------------------------------------\n",
        "# 3. SKU-level split\n",
        "# ---------------------------------------------------------\n",
        "Q4_MONTHS = [\"October\", \"November\", \"December\"]\n",
        "\n",
        "unique_ids = df[\"id\"].unique()\n",
        "train_ids, test_ids = train_test_split(unique_ids, test_size=0.2, random_state=0)\n",
        "\n",
        "train_df = df[df[\"id\"].isin(train_ids)].copy()\n",
        "\n",
        "# test: Q4 rows for unseen SKUs\n",
        "test_condition = df[\"id\"].isin(test_ids)\n",
        "q4_masks = []\n",
        "for m in Q4_MONTHS:\n",
        "    if m in df.columns:\n",
        "        q4_masks.append(df[m] == 1)\n",
        "\n",
        "if q4_masks:\n",
        "    q4_mask_any = q4_masks[0]\n",
        "    for m in q4_masks[1:]:\n",
        "        q4_mask_any = q4_mask_any | m\n",
        "    test_df = df[test_condition & q4_mask_any].copy()\n",
        "else:\n",
        "    # fallback: if Q4 columns absent, just use all rows for test SKUs\n",
        "    test_df = df[test_condition].copy()\n",
        "\n",
        "print(f\"[INFO] Train SKUs: {len(train_ids)}, Test SKUs: {len(test_ids)}\")\n",
        "print(f\"[INFO] Train rows: {len(train_df)}\")\n",
        "print(f\"[INFO] Test rows (Q4 only): {len(test_df)}\")\n",
        "\nprint(f\"[INFO] Unique products in TRAIN: {train_df['id'].nunique()} | TEST: {test_df['id'].nunique()}\")\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Baseline LASSO\n",
        "\n",
        "We drop obvious non-features (`id`, `name`, `demand`) and keep everything else. Then we scale and fit `LassoCV`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---------------------------------------------------------\n",
        "# 4. Baseline LASSO\n",
        "# ---------------------------------------------------------\n",
        "drop_cols = [\"id\", \"name\", \"demand\"]\n",
        "\n",
        "X_train_base = train_df.drop(columns=[c for c in drop_cols if c in train_df.columns])\n",
        "X_train_base = X_train_base.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
        "y_train_base = train_df[\"demand\"].astype(float)\n",
        "\n",
        "X_test_base = test_df.drop(columns=[c for c in drop_cols if c in test_df.columns])\n",
        "X_test_base = X_test_base.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
        "y_test_base = test_df[\"demand\"].astype(float)\n",
        "\n",
        "scaler_base = StandardScaler(with_mean=False)\n",
        "Xtr_base = scaler_base.fit_transform(X_train_base)\n",
        "Xte_base = scaler_base.transform(X_test_base)\n",
        "\n",
        "lasso_base = LassoCV()\n",
        "lasso_base.fit(Xtr_base, y_train_base)\n",
        "y_pred_base = lasso_base.predict(Xte_base)\n",
        "\n",
        "report_metrics(y_test_base, y_pred_base, label=\"[Baseline LASSO] \")\n",
        "show_top_coeffs(lasso_base, X_train_base.columns, k=12)\n",
        "\nvisualize_lasso_cv(lasso_base, \"Baseline LASSO\")\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. (Optional) Light time-style features\n",
        "\n",
        "If the file ever has multiple months per `id`, this shows how to make lag-style features. With one row per `id`, they will just be 0 \u2014 still fine for teaching.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---------------------------------------------------------\n",
        "# 5. Feature-engineered version (lags, MA, price change)\n",
        "# ---------------------------------------------------------\n",
        "df_fe = df.copy()\n",
        "\n",
        "def infer_month_num(row):\n",
        "    for i, m in enumerate(MONTHS, start=1):\n",
        "        if m in row and row[m] == 1:\n",
        "            return i\n",
        "    return np.nan\n",
        "\n",
        "df_fe[\"month_num\"] = df_fe.apply(infer_month_num, axis=1)\n",
        "df_fe = df_fe.sort_values([\"id\", \"month_num\"]).reset_index(drop=True)\n",
        "\n",
        "# Create simple time features per id\n",
        "df_fe[\"lag_demand_1\"] = df_fe.groupby(\"id\")[\"demand\"].shift(1)\n",
        "df_fe[\"ma3_demand\"] = (\n",
        "    df_fe.groupby(\"id\")[\"demand\"].shift(1).rolling(3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        ")\n",
        "df_fe[\"price_change\"] = df_fe.groupby(\"id\")[\"price\"].pct_change()\n",
        "df_fe[[\"lag_demand_1\", \"ma3_demand\", \"price_change\"]] = df_fe[[\"lag_demand_1\", \"ma3_demand\", \"price_change\"]].fillna(0)\n",
        "\n",
        "# Rebuild train/test on FE frame\n",
        "train_fe = df_fe[df_fe[\"id\"].isin(train_ids)].copy()\n",
        "test_fe = df_fe[\n",
        "    df_fe[\"id\"].isin(test_ids)\n",
        "    & (\n",
        "        ((df_fe[\"October\"] == 1) if \"October\" in df_fe.columns else False)\n",
        "        | ((df_fe[\"November\"] == 1) if \"November\" in df_fe.columns else False)\n",
        "        | ((df_fe[\"December\"] == 1) if \"December\" in df_fe.columns else False)\n",
        "    )\n",
        "].copy()\n",
        "\n",
        "drop_cols_fe = [\"id\", \"name\", \"demand\", \"month_num\"]\n",
        "X_train_fe = train_fe.drop(columns=[c for c in drop_cols_fe if c in train_fe.columns])\n",
        "X_train_fe = X_train_fe.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
        "y_train_fe = train_fe[\"demand\"].astype(float)\n",
        "\n",
        "X_test_fe = test_fe.drop(columns=[c for c in drop_cols_fe if c in test_fe.columns])\n",
        "X_test_fe = X_test_fe.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
        "y_test_fe = test_fe[\"demand\"].astype(float)\n",
        "\n",
        "scaler_fe = StandardScaler(with_mean=False)\n",
        "Xtr_fe = scaler_fe.fit_transform(X_train_fe)\n",
        "Xte_fe = scaler_fe.transform(X_test_fe)\n",
        "\n",
        "lasso_fe = LassoCV()\n",
        "lasso_fe.fit(Xtr_fe, y_train_fe)\n",
        "y_pred_fe = lasso_fe.predict(Xte_fe)\n",
        "\n",
        "report_metrics(y_test_fe, y_pred_fe, label=\"[FE LASSO] \")\n",
        "show_top_coeffs(lasso_fe, X_train_fe.columns, k=12)\n",
        "\nvisualize_lasso_cv(lasso_fe, \"FE LASSO\")\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Questions and Reflections\n",
        "\n",
        "1. **Question:** In the baseline model, which variables had the largest coefficients, and do they make sense for retail demand?\n",
        "   **Response:**\n",
        "\n",
        "2. **Question:** Why is splitting by SKU (`id`) a better test of generalization than a random row-wise split here?\n",
        "   **Response:**\n",
        "\n",
        "3. **Question:** If we had more months per SKU, what other time-based features would you add?\n",
        "   **Response:**\n"
      ]
    }
  ]
}